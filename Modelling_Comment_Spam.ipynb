{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "259.797px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "Modelling - Comment Spam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPE9Z_pCgRLS"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:06.568801Z",
          "start_time": "2020-10-07T19:41:05.929106Z"
        },
        "id": "fT4pEJDFgRLT",
        "outputId": "84f0292c-9727-4541-b4fb-cd26f590fe7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "pd.set_option('max_columns', 1000)\n",
        "pd.set_option('max_rows', 1000)\n",
        "\n",
        "english_stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "en_stops = set(stopwords.words('english'))\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO77v7GAgRLX"
      },
      "source": [
        "# Data import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:07.860051Z",
          "start_time": "2020-10-07T19:41:07.802502Z"
        },
        "id": "9Vd5IrkUgRLX",
        "outputId": "70d5fb2d-edbf-4514-eee4-e5f4412e5c51",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "df_data = pd.read_excel(uploaded['Comment Spam.xls'])\n",
        "print(df_data.shape[0])\n",
        "df_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-957a38fe-bd3d-4ca0-acbb-93ad9da523e4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-957a38fe-bd3d-4ca0-acbb-93ad9da523e4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Comment Spam.xls to Comment Spam.xls\n",
            "1300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Comment</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>this song is racist</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>and how many subscribers compared to her over ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>HI! CHECK OUT OUR AWESOME COVERS! AND SAY WHAT...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>well done shakira</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>:D subscribe to me for daily vines</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   No                                            Comment  Class\n",
              "0   1                                this song is racist      0\n",
              "1   2  and how many subscribers compared to her over ...      1\n",
              "2   3  HI! CHECK OUT OUR AWESOME COVERS! AND SAY WHAT...      1\n",
              "3   4                                  well done shakira      0\n",
              "4   5                 :D subscribe to me for daily vines      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:08.981527Z",
          "start_time": "2020-10-07T19:41:08.970330Z"
        },
        "id": "prccdj4CgRLb",
        "outputId": "70c39e33-55a9-4730-ef15-a0c97109800f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_data_processed = df_data[['Comment', 'Class']]\n",
        "df_data_processed.tail()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1295</th>\n",
              "      <td>Awsome&lt;br /&gt;﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296</th>\n",
              "      <td>https://www.tsu.co/KodysMan plz ^^﻿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1297</th>\n",
              "      <td>Sign up for free on TSU and start making money...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>MEGAN FOX AND EMINEM TOGETHER IN A VIDEO  DOES...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1299</th>\n",
              "      <td>Great.This is a song﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Comment  Class\n",
              "1295                                      Awsome<br />﻿      0\n",
              "1296                https://www.tsu.co/KodysMan plz ^^﻿      1\n",
              "1297  Sign up for free on TSU and start making money...      1\n",
              "1298  MEGAN FOX AND EMINEM TOGETHER IN A VIDEO  DOES...      0\n",
              "1299                              Great.This is a song﻿      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:09.360763Z",
          "start_time": "2020-10-07T19:41:09.350929Z"
        },
        "id": "wkS-B3VMgRLe",
        "outputId": "9d41f5c0-d0de-4fb5-dcf2-5a62af017747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "df_data_processed['Class'].value_counts(dropna=False) # the data is already balanced"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    669\n",
              "0    631\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG7CJv4mgRLg"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:10.052666Z",
          "start_time": "2020-10-07T19:41:10.041597Z"
        },
        "id": "jlHedqX9gRLh"
      },
      "source": [
        "'''\n",
        "Function to clean the data, which includes:\n",
        "1. Lowercasing\n",
        "2. Punctuation removal\n",
        "3. Digit removal\n",
        "''' \n",
        "def cleaning(text):\n",
        "    # lowercase\n",
        "    normal = text.lower()\n",
        "    # remove punctuation\n",
        "    normal = re.sub(r'[^\\w\\s]', '', normal) \n",
        "    # remove numbers\n",
        "    normal = re.sub(r'\\d+', ' ', normal)\n",
        "    return normal\n",
        "\n",
        "\n",
        "'''\n",
        "Function to normalize the form of the token (lemmatization)\n",
        "and to remove stopwords\n",
        "'''\n",
        "def normalize_and_remove_stopwords(text):\n",
        "    tokens = nlp(text)\n",
        "    token_new = []\n",
        "    \n",
        "    for k in tokens:\n",
        "        if k.lemma_ not in en_stops:\n",
        "            token_new.append(k.lemma_)\n",
        "\n",
        "    str_clean = ' '.join(token_new)\n",
        "    return str_clean\n",
        "\n",
        "\n",
        "'''\n",
        "Function to do stemming, in this case, we use lemmatization\n",
        "instead of stemming\n",
        "'''\n",
        "def stemming(text):\n",
        "    token = nltk.word_tokenize(text)\n",
        "    stem_sentence = []\n",
        "    for k in token:\n",
        "        stem_word = english_stemmer.stem(k)\n",
        "        stem_sentence.append(stem_word)\n",
        "\n",
        "    stem_sentence_str = ' '.join(stem_sentence)\n",
        "    return stem_sentence_str\n",
        "\n",
        "'''\n",
        "Data preprocessing function, which includes:\n",
        "1. Text cleaning,\n",
        "2. Text normalization, and\n",
        "3. Stopword removal\n",
        "'''\n",
        "def preprocessing(list_text):\n",
        "    text_clean = []\n",
        "    for t in list_text:\n",
        "        normal = cleaning(t)\n",
        "#         normal = stemming(normal)\n",
        "        normal = normalize_and_remove_stopwords(normal)\n",
        "        text_clean.append(normal)\n",
        "    return text_clean"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:22.191334Z",
          "start_time": "2020-10-07T19:41:10.525117Z"
        },
        "id": "E9FgIcgcgRLk",
        "outputId": "b364a28e-91ea-4937-bded-f7dbc39c1913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "raw_text = df_data_processed['Comment']\n",
        "\n",
        "clean_text = preprocessing(raw_text) # do the preprocessing\n",
        "clean_text[:3]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['song racist',\n",
              " 'many subscriber compare -PRON- million',\n",
              " 'hi check -PRON- awesome cover say -PRON- think']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:28.914180Z",
          "start_time": "2020-10-07T19:41:28.882734Z"
        },
        "id": "ZXu6_T86gRLn"
      },
      "source": [
        "# save the clean comments to csv, so we can use it later on\n",
        "df_clean_comment = pd.DataFrame(clean_text, columns=['comment'])\n",
        "df_clean_comment.to_csv('df_clean_comment_no_stemming.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GvoA3YKgRLq"
      },
      "source": [
        "# Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:30.655394Z",
          "start_time": "2020-10-07T19:41:30.651486Z"
        },
        "id": "kJ3fQFySgRLq"
      },
      "source": [
        "class_ = df_data_processed['Class'].tolist() # target variable\n",
        "clean_comment = df_clean_comment['comment'] # clean text to do prediction\n",
        "comment = df_data_processed['Comment'] # raw text to do prediction"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:31.018244Z",
          "start_time": "2020-10-07T19:41:30.977633Z"
        },
        "id": "UFJgxsYwgRLt",
        "outputId": "1bc2856f-2277-47f5-bc45-b94a1edb59bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "'''\n",
        "Function to extract TF (1-gram) features\n",
        "'''\n",
        "def tf_extraction(text, ngram_start, ngram_end):\n",
        "    ngram = CountVectorizer(ngram_range=(ngram_start, ngram_end))\n",
        "    ngram_matrix = ngram.fit_transform(np.array(text)).todense()\n",
        "    feature_names = ngram.get_feature_names()\n",
        "    return ngram_matrix, feature_names\n",
        "\n",
        "# unigram features\n",
        "ngram_feat, feature_names = tf_extraction(clean_comment, 1, 1)\n",
        "print(ngram_feat[:3])\n",
        "print(feature_names[:3])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "['aa', 'aaaaaaa', 'aaacwk']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:32.077557Z",
          "start_time": "2020-10-07T19:41:31.559143Z"
        },
        "code_folding": [],
        "id": "q6PWXvJ_gRLw",
        "outputId": "99509827-23be-4cfc-925d-f8d06625a4e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "Function to extract orthography and url occurence features\n",
        "'''\n",
        "def orthography_and_url_extraction(text):\n",
        "    all_orto_feat = []\n",
        "    for t in text:\n",
        "        capital_count = sum(1 for c in t if c.isupper())\n",
        "        exclamation_count = sum(1 for c in t if c == \"!\")\n",
        "        word_len = len(nltk.word_tokenize(t))\n",
        "        char_len = len(t)\n",
        "        url = 1 if 'http' in t.lower() else 0\n",
        "        orto_feat = [capital_count, exclamation_count, word_len, char_len, url]\n",
        "        all_orto_feat.append(orto_feat)\n",
        "    return all_orto_feat\n",
        "\n",
        "orto_feat = orthography_and_url_extraction(comment)\n",
        "orto_feat[:3]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 4, 19, 0], [0, 0, 10, 55, 0], [44, 3, 14, 57, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T19:41:32.374287Z",
          "start_time": "2020-10-07T19:41:32.302007Z"
        },
        "id": "TI4I5AS3gRLz",
        "outputId": "8a845f3c-18d3-43ae-f4fe-4be65f160c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "'''\n",
        "Function to extract TF-IDF (1-gram) features\n",
        "'''\n",
        "def tf_idf_extraction(text):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(np.array(text)).todense()\n",
        "    return tfidf_matrix\n",
        "\n",
        "# tf-idf features\n",
        "tfidf_feat = tf_idf_extraction(clean_comment)\n",
        "print(tfidf_feat[:3])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skSBND_pgRL2"
      },
      "source": [
        "# Modelling and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T20:24:02.242813Z",
          "start_time": "2020-10-07T19:41:42.852913Z"
        },
        "id": "HmEEsShvgRL2",
        "outputId": "b3403147-b46a-446c-ed4f-73f80298c889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# list of features combinations\n",
        "feat_list = [ngram_feat, tfidf_feat, np.hstack((ngram_feat, orto_feat)), np.hstack((tfidf_feat, orto_feat))]\n",
        "feat_name = ['tf', 'tf-idf', 'tf and orthography', 'tf-idf and orthography']\n",
        "\n",
        "# list of model to do prediction\n",
        "mnb = MultinomialNB()\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "gb = GradientBoostingClassifier(random_state=0)\n",
        "ab = AdaBoostClassifier(random_state=0)\n",
        "knn = KNeighborsClassifier()\n",
        "lr = LogisticRegression(random_state=0)\n",
        "mlp = MLPClassifier(random_state=0)\n",
        "dt = DecisionTreeClassifier(random_state=0)\n",
        "svm = SVC(random_state=0)\n",
        "model_list = [mnb, rf, gb, ab, knn, lr, mlp, dt, svm]\n",
        "model_name = ['Multinomial Naive Bayes', 'Random Forest', 'Gradient Boost', 'Ada Boost',\n",
        "              'kNN', 'Logistic Regression', 'Multilayer Perceptron', 'Decision Tree', 'SVM']\n",
        "\n",
        "# build the model and evaluate the performance of it for each feature combination\n",
        "df_recap = pd.DataFrame()\n",
        "for f, fn in zip(feat_list, feat_name):\n",
        "    print(\"Features : \", fn)\n",
        "    X = f\n",
        "    y = class_\n",
        "    for m, n in zip(model_list, model_name):\n",
        "        scoring = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']\n",
        "        scores = cross_validate(m, X, y, cv=10, scoring=scoring)\n",
        "        acc = np.mean(scores['test_accuracy'])\n",
        "        f1 = np.mean(scores['test_f1_macro'])\n",
        "        precision = np.mean(scores['test_precision_macro'])\n",
        "        recall = np.mean(scores['test_recall_macro'])\n",
        "        print(\"Classifier : \", n)\n",
        "        print(\"Accuracy:\", acc)\n",
        "        print(\"F1-Score:\", f1)\n",
        "        print(\"Precision:\", precision)\n",
        "        print(\"Recall:\", recall)\n",
        "        df_recap = df_recap.append({\n",
        "            'features': fn,\n",
        "            'classifier': n,\n",
        "            'accuracy': acc,\n",
        "            'f1_score': f1,\n",
        "            'precision': precision,\n",
        "            'recall': recall\n",
        "        }, ignore_index=True)\n",
        "        print('='*90)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features :  tf\n",
            "Classifier :  Multinomial Naive Bayes\n",
            "Accuracy: 0.8623076923076922\n",
            "F1-Score: 0.8621813000472567\n",
            "Precision: 0.8647611623735537\n",
            "Recall: 0.8632148880866233\n",
            "==========================================================================================\n",
            "Classifier :  Random Forest\n",
            "Accuracy: 0.9084615384615384\n",
            "F1-Score: 0.9081245627538997\n",
            "Precision: 0.9164923796246713\n",
            "Recall: 0.9102506945790528\n",
            "==========================================================================================\n",
            "Classifier :  Gradient Boost\n",
            "Accuracy: 0.8876923076923078\n",
            "F1-Score: 0.8865498560771108\n",
            "Precision: 0.9043828932902622\n",
            "Recall: 0.8904218087053908\n",
            "==========================================================================================\n",
            "Classifier :  Ada Boost\n",
            "Accuracy: 0.8923076923076924\n",
            "F1-Score: 0.892008549039881\n",
            "Precision: 0.8984433866538515\n",
            "Recall: 0.8937983580474252\n",
            "==========================================================================================\n",
            "Classifier :  kNN\n",
            "Accuracy: 0.8246153846153847\n",
            "F1-Score: 0.82161816177367\n",
            "Precision: 0.8551804498782601\n",
            "Recall: 0.8288169541900885\n",
            "==========================================================================================\n",
            "Classifier :  Logistic Regression\n",
            "Accuracy: 0.8969230769230769\n",
            "F1-Score: 0.8964222845677121\n",
            "Precision: 0.9064962273418417\n",
            "Recall: 0.8987136826689065\n",
            "==========================================================================================\n",
            "Classifier :  Multilayer Perceptron\n",
            "Accuracy: 0.8892307692307693\n",
            "F1-Score: 0.8887072253091768\n",
            "Precision: 0.898146726469748\n",
            "Recall: 0.8911212841366758\n",
            "==========================================================================================\n",
            "Classifier :  Decision Tree\n",
            "Accuracy: 0.9\n",
            "F1-Score: 0.8997800447672943\n",
            "Precision: 0.9049883738779039\n",
            "Recall: 0.9012599845738839\n",
            "==========================================================================================\n",
            "Classifier :  SVM\n",
            "Accuracy: 0.8907692307692308\n",
            "F1-Score: 0.8901398532767837\n",
            "Precision: 0.9014933733147107\n",
            "Recall: 0.8927548405160346\n",
            "==========================================================================================\n",
            "Features :  tf-idf\n",
            "Classifier :  Multinomial Naive Bayes\n",
            "Accuracy: 0.8746153846153846\n",
            "F1-Score: 0.874450582578812\n",
            "Precision: 0.8766928381372352\n",
            "Recall: 0.8751314786995756\n",
            "==========================================================================================\n",
            "Classifier :  Random Forest\n",
            "Accuracy: 0.9046153846153846\n",
            "F1-Score: 0.9041403096267423\n",
            "Precision: 0.9150066239027096\n",
            "Recall: 0.9067562619801427\n",
            "==========================================================================================\n",
            "Classifier :  Gradient Boost\n",
            "Accuracy: 0.8830769230769231\n",
            "F1-Score: 0.8820599459023345\n",
            "Precision: 0.8986755175935898\n",
            "Recall: 0.8857433611164953\n",
            "==========================================================================================\n",
            "Classifier :  Ada Boost\n",
            "Accuracy: 0.8884615384615385\n",
            "F1-Score: 0.8879814594662838\n",
            "Precision: 0.897331916141179\n",
            "Recall: 0.8905171282386768\n",
            "==========================================================================================\n",
            "Classifier :  kNN\n",
            "Accuracy: 0.6307692307692307\n",
            "F1-Score: 0.5811139363628095\n",
            "Precision: 0.7797087251578337\n",
            "Recall: 0.6411196183584243\n",
            "==========================================================================================\n",
            "Classifier :  Logistic Regression\n",
            "Accuracy: 0.8907692307692308\n",
            "F1-Score: 0.8904219346545315\n",
            "Precision: 0.8981372047235976\n",
            "Recall: 0.8925055626897977\n",
            "==========================================================================================\n",
            "Classifier :  Multilayer Perceptron\n",
            "Accuracy: 0.8769230769230768\n",
            "F1-Score: 0.8762989775488995\n",
            "Precision: 0.8865678031019586\n",
            "Recall: 0.8790049179158321\n",
            "==========================================================================================\n",
            "Classifier :  Decision Tree\n",
            "Accuracy: 0.8992307692307693\n",
            "F1-Score: 0.8989333133499903\n",
            "Precision: 0.905580180400413\n",
            "Recall: 0.9007167052992614\n",
            "==========================================================================================\n",
            "Classifier :  SVM\n",
            "Accuracy: 0.9\n",
            "F1-Score: 0.8996408930369479\n",
            "Precision: 0.9083152308012175\n",
            "Recall: 0.9020293722136072\n",
            "==========================================================================================\n",
            "Features :  tf and orthography\n",
            "Classifier :  Multinomial Naive Bayes\n",
            "Accuracy: 0.8638461538461538\n",
            "F1-Score: 0.862131810751403\n",
            "Precision: 0.8731234996676938\n",
            "Recall: 0.8616378335594753\n",
            "==========================================================================================\n",
            "Classifier :  Random Forest\n",
            "Accuracy: 0.9415384615384615\n",
            "F1-Score: 0.9414856643681802\n",
            "Precision: 0.9429441680026107\n",
            "Recall: 0.942042493161896\n",
            "==========================================================================================\n",
            "Classifier :  Gradient Boost\n",
            "Accuracy: 0.9307692307692308\n",
            "F1-Score: 0.9306948404300479\n",
            "Precision: 0.9344655900459558\n",
            "Recall: 0.9319872498976975\n",
            "==========================================================================================\n",
            "Classifier :  Ada Boost\n",
            "Accuracy: 0.9353846153846155\n",
            "F1-Score: 0.9353081568416897\n",
            "Precision: 0.9375600318688806\n",
            "Recall: 0.9359560591253688\n",
            "==========================================================================================\n",
            "Classifier :  kNN\n",
            "Accuracy: 0.7461538461538462\n",
            "F1-Score: 0.7456035719420268\n",
            "Precision: 0.746948214317838\n",
            "Recall: 0.7458385157545606\n",
            "==========================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classifier :  Logistic Regression\n",
            "Accuracy: 0.9330769230769231\n",
            "F1-Score: 0.9330304757050614\n",
            "Precision: 0.9346374452031634\n",
            "Recall: 0.9337048523615687\n",
            "==========================================================================================\n",
            "Classifier :  Multilayer Perceptron\n",
            "Accuracy: 0.9276923076923078\n",
            "F1-Score: 0.9275514064465291\n",
            "Precision: 0.9288282542552212\n",
            "Recall: 0.9276270332590295\n",
            "==========================================================================================\n",
            "Classifier :  Decision Tree\n",
            "Accuracy: 0.9346153846153846\n",
            "F1-Score: 0.934540935217022\n",
            "Precision: 0.9358080958772025\n",
            "Recall: 0.9349141905461866\n",
            "==========================================================================================\n",
            "Classifier :  SVM\n",
            "Accuracy: 0.6369230769230768\n",
            "F1-Score: 0.6339319584415637\n",
            "Precision: 0.6431254278548688\n",
            "Recall: 0.638510992790377\n",
            "==========================================================================================\n",
            "Features :  tf-idf and orthography\n",
            "Classifier :  Multinomial Naive Bayes\n",
            "Accuracy: 0.7569230769230769\n",
            "F1-Score: 0.73918501830004\n",
            "Precision: 0.8188500215410486\n",
            "Recall: 0.7501730558516939\n",
            "==========================================================================================\n",
            "Classifier :  Random Forest\n",
            "Accuracy: 0.9461538461538461\n",
            "F1-Score: 0.946109126398035\n",
            "Precision: 0.9473720961290898\n",
            "Recall: 0.9466509444121384\n",
            "==========================================================================================\n",
            "Classifier :  Gradient Boost\n",
            "Accuracy: 0.9315384615384616\n",
            "F1-Score: 0.9314809941666405\n",
            "Precision: 0.9346976393979215\n",
            "Recall: 0.9326861364174797\n",
            "==========================================================================================\n",
            "Classifier :  Ada Boost\n",
            "Accuracy: 0.9353846153846155\n",
            "F1-Score: 0.9353345579222306\n",
            "Precision: 0.9368218840742104\n",
            "Recall: 0.9359312911901532\n",
            "==========================================================================================\n",
            "Classifier :  kNN\n",
            "Accuracy: 0.7092307692307692\n",
            "F1-Score: 0.7085556976264703\n",
            "Precision: 0.7104770883197657\n",
            "Recall: 0.70915780943766\n",
            "==========================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classifier :  Logistic Regression\n",
            "Accuracy: 0.9130769230769232\n",
            "F1-Score: 0.9130209117355401\n",
            "Precision: 0.9154117546013627\n",
            "Recall: 0.91406495660227\n",
            "==========================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classifier :  Multilayer Perceptron\n",
            "Accuracy: 0.9200000000000002\n",
            "F1-Score: 0.9198941826114568\n",
            "Precision: 0.9214874805256645\n",
            "Recall: 0.9203549689323942\n",
            "==========================================================================================\n",
            "Classifier :  Decision Tree\n",
            "Accuracy: 0.9353846153846155\n",
            "F1-Score: 0.93529622073322\n",
            "Precision: 0.9371884999854736\n",
            "Recall: 0.9356717663037625\n",
            "==========================================================================================\n",
            "Classifier :  SVM\n",
            "Accuracy: 0.6338461538461537\n",
            "F1-Score: 0.6306111924089018\n",
            "Precision: 0.6402614636714334\n",
            "Recall: 0.6354785360265771\n",
            "==========================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-08T00:24:04.335523Z",
          "start_time": "2020-10-08T00:24:04.315670Z"
        },
        "id": "H5DXSvbVgRL7",
        "outputId": "ee1f0986-f38e-4676-8804-921a8964151d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# the recap of scenarios\n",
        "df_recap.sort_values(by='accuracy', ascending=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>classifier</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>features</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.946154</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.946109</td>\n",
              "      <td>tf-idf and orthography</td>\n",
              "      <td>0.947372</td>\n",
              "      <td>0.946651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.941538</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.941486</td>\n",
              "      <td>tf and orthography</td>\n",
              "      <td>0.942944</td>\n",
              "      <td>0.942042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.935385</td>\n",
              "      <td>Ada Boost</td>\n",
              "      <td>0.935335</td>\n",
              "      <td>tf-idf and orthography</td>\n",
              "      <td>0.936822</td>\n",
              "      <td>0.935931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.935385</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.935296</td>\n",
              "      <td>tf-idf and orthography</td>\n",
              "      <td>0.937188</td>\n",
              "      <td>0.935672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.935385</td>\n",
              "      <td>Ada Boost</td>\n",
              "      <td>0.935308</td>\n",
              "      <td>tf and orthography</td>\n",
              "      <td>0.937560</td>\n",
              "      <td>0.935956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.934615</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.934541</td>\n",
              "      <td>tf and orthography</td>\n",
              "      <td>0.935808</td>\n",
              "      <td>0.934914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.933077</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.933030</td>\n",
              "      <td>tf and orthography</td>\n",
              "      <td>0.934637</td>\n",
              "      <td>0.933705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.931538</td>\n",
              "      <td>Gradient Boost</td>\n",
              "      <td>0.931481</td>\n",
              "      <td>tf-idf and orthography</td>\n",
              "      <td>0.934698</td>\n",
              "      <td>0.932686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.930769</td>\n",
              "      <td>Gradient Boost</td>\n",
              "      <td>0.930695</td>\n",
              "      <td>tf and orthography</td>\n",
              "      <td>0.934466</td>\n",
              "      <td>0.931987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.927692</td>\n",
              "      <td>Multilayer Perceptron</td>\n",
              "      <td>0.927551</td>\n",
              "      <td>tf and orthography</td>\n",
              "      <td>0.928828</td>\n",
              "      <td>0.927627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.920000</td>\n",
              "      <td>Multilayer Perceptron</td>\n",
              "      <td>0.919894</td>\n",
              "      <td>tf-idf and orthography</td>\n",
              "      <td>0.921487</td>\n",
              "      <td>0.920355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.913077</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.913021</td>\n",
              "      <td>tf-idf and orthography</td>\n",
              "      <td>0.915412</td>\n",
              "      <td>0.914065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.908462</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.908125</td>\n",
              "      <td>tf</td>\n",
              "      <td>0.916492</td>\n",
              "      <td>0.910251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.904615</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.904140</td>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.915007</td>\n",
              "      <td>0.906756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.900000</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.899780</td>\n",
              "      <td>tf</td>\n",
              "      <td>0.904988</td>\n",
              "      <td>0.901260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.900000</td>\n",
              "      <td>SVM</td>\n",
              "      <td>0.899641</td>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.908315</td>\n",
              "      <td>0.902029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.899231</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.898933</td>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.905580</td>\n",
              "      <td>0.900717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.896923</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.896422</td>\n",
              "      <td>tf</td>\n",
              "      <td>0.906496</td>\n",
              "      <td>0.898714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.892308</td>\n",
              "      <td>Ada Boost</td>\n",
              "      <td>0.892009</td>\n",
              "      <td>tf</td>\n",
              "      <td>0.898443</td>\n",
              "      <td>0.893798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.890769</td>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.890422</td>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.898137</td>\n",
              "      <td>0.892506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.890769</td>\n",
              "      <td>SVM</td>\n",
              "      <td>0.890140</td>\n",
              "      <td>tf</td>\n",
              "      <td>0.901493</td>\n",
              "      <td>0.892755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.889231</td>\n",
              "      <td>Multilayer Perceptron</td>\n",
              "      <td>0.888707</td>\n",
              "      <td>tf</td>\n",
              "      <td>0.898147</td>\n",
              "      <td>0.891121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.888462</td>\n",
              "      <td>Ada Boost</td>\n",
              "      <td>0.887981</td>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.897332</td>\n",
              "      <td>0.890517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.887692</td>\n",
              "      <td>Gradient Boost</td>\n",
              "      <td>0.886550</td>\n",
              "      <td>tf</td>\n",
              "      <td>0.904383</td>\n",
              "      <td>0.890422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.883077</td>\n",
              "      <td>Gradient Boost</td>\n",
              "      <td>0.882060</td>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.898676</td>\n",
              "      <td>0.885743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.876923</td>\n",
              "      <td>Multilayer Perceptron</td>\n",
              "      <td>0.876299</td>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.886568</td>\n",
              "      <td>0.879005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.874615</td>\n",
              "      <td>Multinomial Naive Bayes</td>\n",
              "      <td>0.874451</td>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.876693</td>\n",
              "      <td>0.875131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.863846</td>\n",
              "      <td>Multinomial Naive Bayes</td>\n",
              "      <td>0.862132</td>\n",
              "      <td>tf and orthography</td>\n",
              "      <td>0.873123</td>\n",
              "      <td>0.861638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.862308</td>\n",
              "      <td>Multinomial Naive Bayes</td>\n",
              "      <td>0.862181</td>\n",
              "      <td>tf</td>\n",
              "      <td>0.864761</td>\n",
              "      <td>0.863215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.824615</td>\n",
              "      <td>kNN</td>\n",
              "      <td>0.821618</td>\n",
              "      <td>tf</td>\n",
              "      <td>0.855180</td>\n",
              "      <td>0.828817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.756923</td>\n",
              "      <td>Multinomial Naive Bayes</td>\n",
              "      <td>0.739185</td>\n",
              "      <td>tf-idf and orthography</td>\n",
              "      <td>0.818850</td>\n",
              "      <td>0.750173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.746154</td>\n",
              "      <td>kNN</td>\n",
              "      <td>0.745604</td>\n",
              "      <td>tf and orthography</td>\n",
              "      <td>0.746948</td>\n",
              "      <td>0.745839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.709231</td>\n",
              "      <td>kNN</td>\n",
              "      <td>0.708556</td>\n",
              "      <td>tf-idf and orthography</td>\n",
              "      <td>0.710477</td>\n",
              "      <td>0.709158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.636923</td>\n",
              "      <td>SVM</td>\n",
              "      <td>0.633932</td>\n",
              "      <td>tf and orthography</td>\n",
              "      <td>0.643125</td>\n",
              "      <td>0.638511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.633846</td>\n",
              "      <td>SVM</td>\n",
              "      <td>0.630611</td>\n",
              "      <td>tf-idf and orthography</td>\n",
              "      <td>0.640261</td>\n",
              "      <td>0.635479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.630769</td>\n",
              "      <td>kNN</td>\n",
              "      <td>0.581114</td>\n",
              "      <td>tf-idf</td>\n",
              "      <td>0.779709</td>\n",
              "      <td>0.641120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    accuracy               classifier  f1_score                features  \\\n",
              "28  0.946154            Random Forest  0.946109  tf-idf and orthography   \n",
              "19  0.941538            Random Forest  0.941486      tf and orthography   \n",
              "30  0.935385                Ada Boost  0.935335  tf-idf and orthography   \n",
              "34  0.935385            Decision Tree  0.935296  tf-idf and orthography   \n",
              "21  0.935385                Ada Boost  0.935308      tf and orthography   \n",
              "25  0.934615            Decision Tree  0.934541      tf and orthography   \n",
              "23  0.933077      Logistic Regression  0.933030      tf and orthography   \n",
              "29  0.931538           Gradient Boost  0.931481  tf-idf and orthography   \n",
              "20  0.930769           Gradient Boost  0.930695      tf and orthography   \n",
              "24  0.927692    Multilayer Perceptron  0.927551      tf and orthography   \n",
              "33  0.920000    Multilayer Perceptron  0.919894  tf-idf and orthography   \n",
              "32  0.913077      Logistic Regression  0.913021  tf-idf and orthography   \n",
              "1   0.908462            Random Forest  0.908125                      tf   \n",
              "10  0.904615            Random Forest  0.904140                  tf-idf   \n",
              "7   0.900000            Decision Tree  0.899780                      tf   \n",
              "17  0.900000                      SVM  0.899641                  tf-idf   \n",
              "16  0.899231            Decision Tree  0.898933                  tf-idf   \n",
              "5   0.896923      Logistic Regression  0.896422                      tf   \n",
              "3   0.892308                Ada Boost  0.892009                      tf   \n",
              "14  0.890769      Logistic Regression  0.890422                  tf-idf   \n",
              "8   0.890769                      SVM  0.890140                      tf   \n",
              "6   0.889231    Multilayer Perceptron  0.888707                      tf   \n",
              "12  0.888462                Ada Boost  0.887981                  tf-idf   \n",
              "2   0.887692           Gradient Boost  0.886550                      tf   \n",
              "11  0.883077           Gradient Boost  0.882060                  tf-idf   \n",
              "15  0.876923    Multilayer Perceptron  0.876299                  tf-idf   \n",
              "9   0.874615  Multinomial Naive Bayes  0.874451                  tf-idf   \n",
              "18  0.863846  Multinomial Naive Bayes  0.862132      tf and orthography   \n",
              "0   0.862308  Multinomial Naive Bayes  0.862181                      tf   \n",
              "4   0.824615                      kNN  0.821618                      tf   \n",
              "27  0.756923  Multinomial Naive Bayes  0.739185  tf-idf and orthography   \n",
              "22  0.746154                      kNN  0.745604      tf and orthography   \n",
              "31  0.709231                      kNN  0.708556  tf-idf and orthography   \n",
              "26  0.636923                      SVM  0.633932      tf and orthography   \n",
              "35  0.633846                      SVM  0.630611  tf-idf and orthography   \n",
              "13  0.630769                      kNN  0.581114                  tf-idf   \n",
              "\n",
              "    precision    recall  \n",
              "28   0.947372  0.946651  \n",
              "19   0.942944  0.942042  \n",
              "30   0.936822  0.935931  \n",
              "34   0.937188  0.935672  \n",
              "21   0.937560  0.935956  \n",
              "25   0.935808  0.934914  \n",
              "23   0.934637  0.933705  \n",
              "29   0.934698  0.932686  \n",
              "20   0.934466  0.931987  \n",
              "24   0.928828  0.927627  \n",
              "33   0.921487  0.920355  \n",
              "32   0.915412  0.914065  \n",
              "1    0.916492  0.910251  \n",
              "10   0.915007  0.906756  \n",
              "7    0.904988  0.901260  \n",
              "17   0.908315  0.902029  \n",
              "16   0.905580  0.900717  \n",
              "5    0.906496  0.898714  \n",
              "3    0.898443  0.893798  \n",
              "14   0.898137  0.892506  \n",
              "8    0.901493  0.892755  \n",
              "6    0.898147  0.891121  \n",
              "12   0.897332  0.890517  \n",
              "2    0.904383  0.890422  \n",
              "11   0.898676  0.885743  \n",
              "15   0.886568  0.879005  \n",
              "9    0.876693  0.875131  \n",
              "18   0.873123  0.861638  \n",
              "0    0.864761  0.863215  \n",
              "4    0.855180  0.828817  \n",
              "27   0.818850  0.750173  \n",
              "22   0.746948  0.745839  \n",
              "31   0.710477  0.709158  \n",
              "26   0.643125  0.638511  \n",
              "35   0.640261  0.635479  \n",
              "13   0.779709  0.641120  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-07T20:24:02.254704Z",
          "start_time": "2020-10-07T20:24:02.247958Z"
        },
        "id": "53CgiO8AgRL-"
      },
      "source": [
        "df_recap.to_csv('df_recap.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfzjDEwegRMA"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}